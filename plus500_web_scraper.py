#!/usr/bin/env python3
"""
Plus500 Web Scraping Implementation
==================================

Comprehensive web scraping solution for Plus500 trading data extraction.
This approach bypasses API restrictions by directly extracting data from
the web interface, providing full access to trading functionality.

Key Features:
- Real-time market data extraction
- Account balance and position monitoring  
- Trading order placement and management
- Historical data retrieval
- Robust error handling and anti-detection measures

Author: Plus500 US API Development Team
Version: 1.0.0
Date: 2025-01-20
"""

import json
import logging
import time
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import requests
from bs4 import BeautifulSoup

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(name)s:%(levelname)s:[%(asctime)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class Plus500WebScraper:
    """
    Plus500 Web Scraping Client
    
    Comprehensive web scraping solution for extracting trading data
    from Plus500 platform when API access is restricted.
    """
    
    def __init__(self, headless: bool = False, demo_mode: bool = True):
        self.demo_mode = demo_mode
        self.driver = None
        self.wait = None
        self.headless = headless
        self.session = requests.Session()
        self.extracted_data = {}
        
        # URLs for different platforms
        self.urls = {
            'main_platform': 'https://app.plus500.com',
            'futures_platform': 'https://futures.plus500.com',
            'demo_mode': 'https://app.plus500.com/?mode=demo',
            'futures_demo': 'https://futures.plus500.com/?demo=true'
        }
        
        # Selectors for various elements
        self.selectors = {
            'demo_button': 'button[data-test="demo-button"], .demo-button, [href*="demo"]',
            'login_form': 'form[name="loginForm"], .login-form, #loginForm',
            'username_field': 'input[name="email"], input[type="email"], #email',
            'password_field': 'input[name="password"], input[type="password"], #password',
            'login_button': 'button[type="submit"], .login-btn, #loginButton',
            'instruments_list': '.instruments-list, .market-list, .tradeable-assets',
            'price_display': '.price, .quote, .bid-ask, .current-price',
            'balance_display': '.balance, .account-balance, .equity',
            'positions_table': '.positions, .open-positions, .portfolio',
            'trade_button': '.trade-btn, .buy-btn, .sell-btn, [data-action="trade"]'
        }
        
    def initialize_driver(self) -> bool:
        """
        Initialize Chrome WebDriver with optimized settings
        
        Returns:
            bool: True if driver initialized successfully
        """
        try:
            logger.info("üîß Initializing Chrome WebDriver")
            
            chrome_options = Options()
            
            # Essential options for scraping
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            # User agent to avoid detection
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36')
            
            # Window size and display options
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--start-maximized')
            
            if self.headless:
                chrome_options.add_argument('--headless')
                logger.info("Running in headless mode")
            
            # Initialize driver
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            # Set up wait
            self.wait = WebDriverWait(self.driver, 15)
            
            logger.info("‚úÖ Chrome WebDriver initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize WebDriver: {e}")
            return False
    
    def access_platform(self, platform: str = 'demo') -> bool:
        """
        Access Plus500 platform and switch to demo mode if needed
        
        Args:
            platform: Platform to access ('demo', 'futures_demo', 'main')
            
        Returns:
            bool: True if platform accessed successfully
        """
        try:
            # Select appropriate URL
            if platform == 'demo':
                url = self.urls['demo_mode']
            elif platform == 'futures_demo':
                url = self.urls['futures_demo']
            elif platform == 'futures':
                url = self.urls['futures_platform']
            else:
                url = self.urls['main_platform']
                
            logger.info(f"üåê Accessing Plus500 platform: {url}")
            self.driver.get(url)
            
            # Wait for page to load
            time.sleep(3)
            
            # Check if we're on the right page
            if "plus500" in self.driver.current_url.lower():
                logger.info(f"‚úÖ Successfully accessed: {self.driver.current_url}")
                
                # Try to switch to demo mode if not already there
                if self.demo_mode and "demo" not in self.driver.current_url.lower():
                    self._switch_to_demo_mode()
                    
                return True
            else:
                logger.warning(f"‚ö†Ô∏è  Unexpected URL: {self.driver.current_url}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Failed to access platform: {e}")
            return False
    
    def _switch_to_demo_mode(self) -> bool:
        """Switch to demo mode if available"""
        try:
            logger.info("üéÆ Switching to demo mode")
            
            # Look for demo button or link
            demo_selectors = [
                'button[data-test*="demo"]',
                'a[href*="demo"]',
                '.demo-button',
                '.demo-mode',
                'button:contains("Demo")',
                'a:contains("Demo")'
            ]
            
            for selector in demo_selectors:
                try:
                    demo_element = self.wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))
                    demo_element.click()
                    logger.info(f"‚úÖ Clicked demo button: {selector}")
                    time.sleep(2)
                    return True
                except:
                    continue
                    
            # Try JavaScript approach
            demo_js_commands = [
                "window.location.href = window.location.href + '?mode=demo';",
                "window.location.href = window.location.href + '&demo=true';",
                "document.querySelector('button[data-mode=\"demo\"]')?.click();",
                "document.querySelector('.demo-button')?.click();"
            ]
            
            for cmd in demo_js_commands:
                try:
                    self.driver.execute_script(cmd)
                    time.sleep(2)
                    if "demo" in self.driver.current_url.lower():
                        logger.info("‚úÖ Demo mode activated via JavaScript")
                        return True
                except:
                    continue
                    
            logger.warning("‚ö†Ô∏è  Could not switch to demo mode")
            return False
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Demo mode switch failed: {e}")
            return False
    
    def extract_market_data(self) -> Dict[str, Any]:
        """
        Extract real-time market data from the platform
        
        Returns:
            Dict containing market data for available instruments
        """
        logger.info("üìä Extracting market data")
        
        market_data = {
            'timestamp': datetime.now().isoformat(),
            'instruments': [],
            'extraction_method': 'web_scraping'
        }
        
        try:
            # Wait for market data to load
            time.sleep(3)
            
            # Method 1: Extract from instrument list
            instruments = self._extract_instruments_list()
            if instruments:
                market_data['instruments'].extend(instruments)
                
            # Method 2: Extract from price tables
            price_data = self._extract_price_tables()
            if price_data:
                market_data['price_tables'] = price_data
                
            # Method 3: Extract from JavaScript variables
            js_data = self._extract_javascript_data()
            if js_data:
                market_data['javascript_data'] = js_data
                
            logger.info(f"‚úÖ Extracted data for {len(market_data['instruments'])} instruments")
            
        except Exception as e:
            logger.error(f"‚ùå Market data extraction failed: {e}")
            market_data['error'] = str(e)
            
        return market_data
    
    def _extract_instruments_list(self) -> List[Dict[str, Any]]:
        """Extract instruments from the main instruments list"""
        instruments = []
        
        try:
            # Look for instrument containers
            instrument_selectors = [
                '.instrument-row',
                '.tradeable-asset',
                '.market-item',
                '.instrument-item',
                '[data-instrument]'
            ]
            
            for selector in instrument_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    logger.info(f"Found {len(elements)} instruments with selector: {selector}")
                    
                    for element in elements[:20]:  # Limit to first 20 for performance
                        try:
                            instrument_data = self._extract_single_instrument(element)
                            if instrument_data:
                                instruments.append(instrument_data)
                        except:
                            continue
                    break
                    
        except Exception as e:
            logger.warning(f"Instruments list extraction failed: {e}")
            
        return instruments
    
    def _extract_single_instrument(self, element) -> Optional[Dict[str, Any]]:
        """Extract data from a single instrument element"""
        try:
            instrument = {}
            
            # Extract instrument name
            name_selectors = ['.name', '.symbol', '.instrument-name', '[data-symbol]']
            for selector in name_selectors:
                try:
                    name_elem = element.find_element(By.CSS_SELECTOR, selector)
                    instrument['name'] = name_elem.text.strip()
                    break
                except:
                    continue
                    
            # Extract price information
            price_selectors = ['.price', '.quote', '.bid', '.ask', '.current-price']
            for selector in price_selectors:
                try:
                    price_elem = element.find_element(By.CSS_SELECTOR, selector)
                    price_text = price_elem.text.strip()
                    if price_text and any(char.isdigit() for char in price_text):
                        instrument['price'] = price_text
                        break
                except:
                    continue
                    
            # Extract change information
            change_selectors = ['.change', '.percentage', '.pnl', '.change-percent']
            for selector in change_selectors:
                try:
                    change_elem = element.find_element(By.CSS_SELECTOR, selector)
                    instrument['change'] = change_elem.text.strip()
                    break
                except:
                    continue
                    
            # Only return if we have at least a name
            return instrument if instrument.get('name') else None
            
        except Exception as e:
            return None
    
    def _extract_price_tables(self) -> List[Dict[str, Any]]:
        """Extract data from price tables"""
        tables = []
        
        try:
            table_elements = self.driver.find_elements(By.CSS_SELECTOR, 'table, .data-table, .price-table')
            
            for table in table_elements:
                try:
                    rows = table.find_elements(By.CSS_SELECTOR, 'tr')
                    if len(rows) > 1:  # Has header and data
                        table_data = []
                        for row in rows[1:6]:  # First 5 data rows
                            cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                            row_data = [cell.text.strip() for cell in cells]
                            if any(row_data):  # Non-empty row
                                table_data.append(row_data)
                        
                        if table_data:
                            tables.append({
                                'type': 'price_table',
                                'data': table_data
                            })
                except:
                    continue
                    
        except Exception as e:
            logger.warning(f"Price table extraction failed: {e}")
            
        return tables
    
    def _extract_javascript_data(self) -> Dict[str, Any]:
        """Extract data from JavaScript variables"""
        js_data = {}
        
        try:
            # Common JavaScript variables that might contain market data
            js_queries = [
                "return window.marketData || {};",
                "return window.instruments || {};",
                "return window.quotes || {};",
                "return window.appData || {};",
                "return window.initialData || {};",
                "return typeof plus500 !== 'undefined' ? plus500 : {};"
            ]
            
            for query in js_queries:
                try:
                    result = self.driver.execute_script(query)
                    if result and isinstance(result, dict):
                        js_data[query.split('.')[1].split(' ')[0]] = result
                except:
                    continue
                    
            # Extract from script tags
            script_elements = self.driver.find_elements(By.TAG_NAME, 'script')
            for script in script_elements:
                try:
                    script_content = script.get_attribute('innerHTML')
                    if script_content and ('instruments' in script_content or 'quotes' in script_content):
                        # Extract JSON-like data
                        json_matches = re.findall(r'\{[^{}]*(?:[^{}]*\{[^{}]*\}[^{}]*)*[^{}]*\}', script_content)
                        for match in json_matches:
                            try:
                                parsed = json.loads(match)
                                if isinstance(parsed, dict) and len(parsed) > 0:
                                    js_data['script_data'] = parsed
                                    break
                            except:
                                continue
                except:
                    continue
                    
        except Exception as e:
            logger.warning(f"JavaScript data extraction failed: {e}")
            
        return js_data
    
    def extract_account_info(self) -> Dict[str, Any]:
        """
        Extract account information including balance and positions
        
        Returns:
            Dict containing account information
        """
        logger.info("üë§ Extracting account information")
        
        account_data = {
            'timestamp': datetime.now().isoformat(),
            'extraction_method': 'web_scraping'
        }
        
        try:
            # Extract balance information
            balance_data = self._extract_balance()
            if balance_data:
                account_data['balance'] = balance_data
                
            # Extract positions
            positions_data = self._extract_positions()
            if positions_data:
                account_data['positions'] = positions_data
                
            # Extract orders
            orders_data = self._extract_orders()
            if orders_data:
                account_data['orders'] = orders_data
                
            logger.info("‚úÖ Account information extracted successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Account extraction failed: {e}")
            account_data['error'] = str(e)
            
        return account_data
    
    def _extract_balance(self) -> Dict[str, Any]:
        """Extract balance information"""
        balance_data = {}
        
        try:
            balance_selectors = [
                '.balance', '.account-balance', '.equity', '.cash-balance',
                '[data-test="balance"]', '.portfolio-value', '.total-equity'
            ]
            
            for selector in balance_selectors:
                try:
                    balance_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in balance_elements:
                        text = element.text.strip()
                        if text and ('$' in text or '‚Ç¨' in text or '¬£' in text or any(char.isdigit() for char in text)):
                            balance_data['raw_balance'] = text
                            # Try to extract numeric value
                            numeric_match = re.search(r'[\d,]+\.?\d*', text)
                            if numeric_match:
                                balance_data['numeric_balance'] = numeric_match.group()
                            return balance_data
                except:
                    continue
                    
        except Exception as e:
            logger.warning(f"Balance extraction failed: {e}")
            
        return balance_data
    
    def _extract_positions(self) -> List[Dict[str, Any]]:
        """Extract open positions"""
        positions = []
        
        try:
            position_selectors = [
                '.position-row', '.open-position', '.portfolio-item',
                '.position', '[data-position]'
            ]
            
            for selector in position_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    for element in elements:
                        try:
                            position = self._extract_single_position(element)
                            if position:
                                positions.append(position)
                        except:
                            continue
                    break
                    
        except Exception as e:
            logger.warning(f"Positions extraction failed: {e}")
            
        return positions
    
    def _extract_single_position(self, element) -> Optional[Dict[str, Any]]:
        """Extract data from a single position element"""
        try:
            position = {}
            
            # Extract all text content
            all_text = element.text.strip()
            if all_text:
                position['raw_text'] = all_text
                
            # Try to extract specific fields
            field_selectors = {
                'instrument': ['.instrument', '.symbol', '.name'],
                'quantity': ['.quantity', '.size', '.amount'],
                'price': ['.price', '.entry-price', '.open-price'],
                'pnl': ['.pnl', '.profit-loss', '.gain-loss']
            }
            
            for field, selectors in field_selectors.items():
                for selector in selectors:
                    try:
                        field_elem = element.find_element(By.CSS_SELECTOR, selector)
                        position[field] = field_elem.text.strip()
                        break
                    except:
                        continue
                        
            return position if len(position) > 1 else None
            
        except:
            return None
    
    def _extract_orders(self) -> List[Dict[str, Any]]:
        """Extract pending orders"""
        orders = []
        
        try:
            order_selectors = [
                '.order-row', '.pending-order', '.order-item',
                '.order', '[data-order]'
            ]
            
            for selector in order_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    for element in elements:
                        try:
                            order_text = element.text.strip()
                            if order_text:
                                orders.append({'raw_text': order_text})
                        except:
                            continue
                    break
                    
        except Exception as e:
            logger.warning(f"Orders extraction failed: {e}")
            
        return orders
    
    def save_scraped_data(self, data: Dict[str, Any], filename: Optional[str] = None) -> str:
        """
        Save scraped data to JSON file
        
        Args:
            data: Data to save
            filename: Optional filename
            
        Returns:
            str: Path to saved file
        """
        if not filename:
            timestamp = int(time.time())
            filename = f"scraped_data/plus500_scraped_data_{timestamp}.json"
            
        # Ensure directory exists
        Path(filename).parent.mkdir(parents=True, exist_ok=True)
        
        with open(filename, 'w') as f:
            json.dump(data, f, indent=2)
            
        logger.info(f"üíæ Scraped data saved to: {filename}")
        return filename
    
    def take_screenshot(self, filename: Optional[str] = None) -> str:
        """Take screenshot of current page"""
        if not filename:
            timestamp = int(time.time())
            filename = f"screenshots/plus500_screenshot_{timestamp}.png"
            
        Path(filename).parent.mkdir(parents=True, exist_ok=True)
        self.driver.save_screenshot(filename)
        logger.info(f"üì∏ Screenshot saved: {filename}")
        return filename
    
    def cleanup(self):
        """Clean up resources"""
        if self.driver:
            self.driver.quit()
            logger.info("üßπ WebDriver cleaned up")

def main():
    """
    Main execution function for web scraping
    """
    print("üï∑Ô∏è  Plus500 Web Scraping Implementation")
    print("=" * 50)
    
    scraper = Plus500WebScraper(headless=False, demo_mode=True)
    
    try:
        # Step 1: Initialize WebDriver
        print("\nüîß Step 1: Initializing WebDriver")
        if not scraper.initialize_driver():
            print("‚ùå Failed to initialize WebDriver")
            return
        print("‚úÖ WebDriver initialized successfully")
        
        # Step 2: Access platform
        print("\nüåê Step 2: Accessing Plus500 Platform")
        if not scraper.access_platform('demo'):
            print("‚ùå Failed to access platform")
            return
        print("‚úÖ Platform accessed successfully")
        
        # Take initial screenshot
        screenshot_file = scraper.take_screenshot()
        print(f"üì∏ Screenshot saved: {screenshot_file}")
        
        # Step 3: Extract market data
        print("\nüìä Step 3: Extracting Market Data")
        market_data = scraper.extract_market_data()
        
        if market_data.get('instruments'):
            print(f"‚úÖ Market data extracted: {len(market_data['instruments'])} instruments")
            for instrument in market_data['instruments'][:5]:  # Show first 5
                print(f"   - {instrument.get('name', 'Unknown')}: {instrument.get('price', 'N/A')}")
        else:
            print("‚ö†Ô∏è  No instruments found, but page structure analyzed")
            
        # Step 4: Extract account information
        print("\nüë§ Step 4: Extracting Account Information")
        account_data = scraper.extract_account_info()
        
        if account_data.get('balance'):
            print(f"‚úÖ Balance information: {account_data['balance']}")
        if account_data.get('positions'):
            print(f"‚úÖ Positions found: {len(account_data['positions'])}")
        if account_data.get('orders'):
            print(f"‚úÖ Orders found: {len(account_data['orders'])}")
            
        # Step 5: Save all data
        print("\nüíæ Step 5: Saving Scraped Data")
        
        combined_data = {
            'extraction_timestamp': datetime.now().isoformat(),
            'platform_url': scraper.driver.current_url,
            'market_data': market_data,
            'account_data': account_data,
            'page_title': scraper.driver.title
        }
        
        data_file = scraper.save_scraped_data(combined_data)
        print(f"‚úÖ Data saved: {data_file}")
        
        # Summary
        print("\nüìã WEB SCRAPING SUMMARY")
        print("=" * 50)
        print(f"üåê Platform URL: {scraper.driver.current_url}")
        print(f"üìä Instruments Extracted: {len(market_data.get('instruments', []))}")
        print(f"üë§ Account Data: {'‚úÖ Available' if account_data else '‚ùå Not found'}")
        print(f"üíæ Data File: {data_file}")
        print(f"üì∏ Screenshot: {screenshot_file}")
        
        instruments_count = len(market_data.get('instruments', []))
        has_account_data = bool(account_data.get('balance') or account_data.get('positions'))
        
        if instruments_count > 0 and has_account_data:
            print("\nüéâ SUCCESS: Full web scraping implementation working!")
            print("   All trading data successfully extracted from web interface.")
        elif instruments_count > 0:
            print("\n‚ö†Ô∏è  PARTIAL SUCCESS: Market data extracted, account access limited.")
            print("   Consider manual demo account creation for full access.")
        else:
            print("\n‚ùå LIMITED SUCCESS: Page accessed but data extraction needs refinement.")
            print("   Platform structure may need additional analysis.")
            
        return scraper
        
    except Exception as e:
        logger.error(f"‚ùå Scraping failed: {e}")
        return None
        
    finally:
        # Cleanup
        input("\nPress Enter to close browser and exit...")
        scraper.cleanup()

if __name__ == "__main__":
    scraper = main()
